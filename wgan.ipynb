{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 598,
     "status": "ok",
     "timestamp": 1643384863549,
     "user": {
      "displayName": "jiaming li",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07336273892212727484"
     },
     "user_tz": -480
    },
    "id": "JW-bhrg1QEy2",
    "outputId": "2f5391ce-f92f-44f4-b8f3-411654e22916"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 1.x selected.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 1.x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Vkuok1zQfLC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1643384863552,
     "user": {
      "displayName": "jiaming li",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07336273892212727484"
     },
     "user_tz": -480
    },
    "id": "yRr-33x-K4V2",
    "outputId": "ec466a14-5b51-4fe2-cfc4-cd64f28fb2a9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\n!cp -r \"/content/drive/MyDrive/test/get_cifar.py\" \"/content/\"\\n!cp -r \"/content/drive/MyDrive/test/load_cifar.py\" \"/content/\"\\n!cp -r \"/content/drive/MyDrive/test/cifar-10-batches-py\" \"/content/cifar/\"\\n!cp -r \"/content/drive/MyDrive/test/WGAN-tensorflow-master/get_svhn.py\" \"/content/\"\\n!cp -r \"/content/drive/MyDrive/test/WGAN-tensorflow-master/load_svhn.py\" \"/content/\"\\n!cp -r \"/content/drive/MyDrive/test/inception_score.py\" \"/content/\"\\n!cp -r \"/content/drive/MyDrive/test/plot.py\" \"/content/\"\\n!cp -r \"/content/drive/MyDrive/test/stat\" \"/content/\"\\n!cp \"/content/drive/MyDrive/test/fid.py\" \"/content/\"\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "!cp -r \"/content/drive/MyDrive/test/get_cifar.py\" \"/content/\"\n",
    "!cp -r \"/content/drive/MyDrive/test/load_cifar.py\" \"/content/\"\n",
    "!cp -r \"/content/drive/MyDrive/test/cifar-10-batches-py\" \"/content/cifar/\"\n",
    "!cp -r \"/content/drive/MyDrive/test/get_svhn.py\" \"/content/\"\n",
    "!cp -r \"/content/drive/MyDrive/test/load_svhn.py\" \"/content/\"\n",
    "!cp -r \"/content/drive/MyDrive/test/inception_score.py\" \"/content/\"\n",
    "!cp -r \"/content/drive/MyDrive/test/plot.py\" \"/content/\"\n",
    "!cp -r \"/content/drive/MyDrive/test/stat\" \"/content/\"\n",
    "!cp \"/content/drive/MyDrive/test/fid.py\" \"/content/\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9lW-CpGZJi9h"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3878,
     "status": "ok",
     "timestamp": 1643384867419,
     "user": {
      "displayName": "jiaming li",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07336273892212727484"
     },
     "user_tz": -480
    },
    "id": "Usi1PPyw11ok",
    "outputId": "2f812dd4-d70b-47f3-c54e-351fb5aa06ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /content/inception_score.py:74: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n",
      "WARNING:tensorflow:From /content/inception_score.py:75: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/inception_score.py:79: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/inception_score.py:80: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\n",
      "\n",
      "1.15.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "from six.moves import xrange\n",
    "import tensorflow.contrib.slim as slim\n",
    "from __future__ import print_function, division\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.layers as ly\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from functools import partial\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import time\n",
    "import collections\n",
    "import pickle\n",
    "import scipy.misc\n",
    "\n",
    "#from scipy.misc import imsave\n",
    "import imageio\n",
    "from PIL import Image #PIL pakage name is Pillow\n",
    "\n",
    "from load_svhn import load_svhn\n",
    "from load_cifar import load_cifar\n",
    "import inception_score\n",
    "from inception_score import get_inception_score as fget_inception_score\n",
    "import plot\n",
    "\n",
    "import fid\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)  # 图像显示大小\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ndmO-na8Yx0a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vge1YaEB0Ar9"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "noise_dim = 128\n",
    "\n",
    "device = '/gpu:0'\n",
    "\n",
    "# update Citers times of critic in one iter(unless i < 25 or i % 500 == 0, i is iterstep)\n",
    "Citers = 5 # For WGAN and WGAN-GP, number of critic iters per gen iter\n",
    "# the upper bound and lower bound of parameters in critic\n",
    "clamp_lower = -0.01\n",
    "clamp_upper = 0.01\n",
    "# whether to use mlp or dcgan stucture\n",
    "is_mlp = False\n",
    "\n",
    "\n",
    "\n",
    "# 'wgan-gp' for gp WGAN and 'wgan' for WGAN with clip and 'dcgan' for DCGAN\n",
    "mode = 'wgan'\n",
    "# whether to use SVHN or MNIST, set false and MNIST is used\n",
    "data = 'svhn'\n",
    "\n",
    "if data == 'mnist':\n",
    "  plt.rcParams['image.interpolation'] = 'nearest'  # 最近邻差值: 像素为正方形\n",
    "  plt.rcParams['image.cmap'] = 'gray' # 使用灰度输出而不是彩色输出\n",
    "  OUTPUT_DIM = 1*28*28 \n",
    "  channel = 1\n",
    "  s = 28 #img size\n",
    "\n",
    "else:\n",
    "  OUTPUT_DIM = 3*32*32\n",
    "  channel = 3\n",
    "  s = 32 #img size\n",
    "\n",
    "\n",
    "\n",
    "# if 'wgan-gp' is chosen the corresponding lambda must be filled\n",
    "lam = 10. # Gradient penalty lambda hyperparameter\n",
    "\n",
    "if mode =='wgan-gp':\n",
    "  learning_rate_G = 1e-4\n",
    "  learning_rate_C = 1e-4\n",
    "elif mode == 'wgan':\n",
    "  learning_rate_G = 3e-5\n",
    "  learning_rate_C = 3e-5\n",
    "elif mode == 'dcgan':\n",
    "  learning_rate_G = 2e-4\n",
    "  learning_rate_C = 2e-4\n",
    "\n",
    " # Number of pixels in each iamge\n",
    "\n",
    "Dim = 64\n",
    "if mode == 'wgan':\n",
    "  bn = 0\n",
    "else:\n",
    "  bn = 1\n",
    "# directory to store log, including loss and grad_norm of generator and critic\n",
    "log_dir = './log_wgan'\n",
    "ckpt_dir = './ckpt_wgan'\n",
    "img_dir = './'+mode+'_'+data\n",
    "if not os.path.exists(ckpt_dir):\n",
    "    os.makedirs(ckpt_dir)\n",
    "if not os.path.exists(img_dir):\n",
    "    os.makedirs(img_dir)\n",
    "# max iter step, note the one step indicates that a Citers updates of critic and one update of generator\n",
    "max_iter_step = 20000  # How many generator iterations to train for \n",
    "\n",
    "show_every = 100\n",
    "\n",
    "FID = True\n",
    "if data == 'mnist':\n",
    "  FID = False\n",
    "\n",
    "IS = False\n",
    "if data == 'cifar':\n",
    "  IS =True\n",
    "\n",
    "FID_STEP = 500 # FID evaluation every FID_STEP\n",
    "# FID evaluation.\n",
    "FID_EVAL_SIZE = 5000 # Number of samples for evaluation\n",
    "FID_SAMPLE_BATCH_SIZE = 100  # Batch size of generating samples, lower to save GPU memory\n",
    "FID_BATCH_SIZE = 200 # Batch size for final FID calculation i.e. inception propagation etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aVdE6HhF2-hc"
   },
   "outputs": [],
   "source": [
    "def disp_images(images,iter):\n",
    "  images = np.reshape(images, [images.shape[0], -1, channel])\n",
    "  sqrtn = int(np.ceil(np.sqrt(images.shape[0])))\n",
    "  sqrtimg = int(np.ceil(np.sqrt(images.shape[1])))\n",
    "  figure = plt.figure(figsize=(sqrtn, sqrtn))\n",
    "  gs = gridspec.GridSpec(sqrtn, sqrtn)  # 指定放置子图的网格的几何形状 行、列\n",
    "  gs.update(wspace=0.05, hspace=0.05)  # 子图之间宽度空间、高度空间\n",
    "  for i, img in enumerate(images): # 列举数据、数据下标\n",
    "    ax = plt.subplot(gs[i])\n",
    "    plt.axis('off')\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_aspect('equal')\n",
    "    if channel == 3:\n",
    "      plt.imshow(img.reshape([sqrtimg, sqrtimg, channel]))\n",
    "    elif channel == 1:\n",
    "      plt.imshow(img.reshape([sqrtimg, sqrtimg]))\n",
    "  save_path = img_dir + '/{}-{}-samples_{}.png'.format(mode,data,iter) # 要保存为的图片\n",
    "  plt.savefig(save_path)\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c9eD9seh5U9v"
   },
   "outputs": [],
   "source": [
    "#leaky relu\n",
    "def lrelu(x, alpha=0.01):\n",
    "  a = tf.maximum(x, alpha*x)\n",
    "  return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V-VjPtS8R7hT"
   },
   "outputs": [],
   "source": [
    "def sample_noise(batch_size,dim):\n",
    "  # 从均匀分布中输出随机值 \n",
    "  random_noise = tf.random_uniform(maxval=1,minval=-1,shape=[batch_size,dim])\n",
    "  \n",
    "  return random_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C7jwhNmC0IHi"
   },
   "outputs": [],
   "source": [
    "def generator_conv(n_samples, x=None):\n",
    "  if x is None:\n",
    "    x = sample_noise(n_samples, noise_dim)\n",
    "  with tf.variable_scope(\"generator\"):\n",
    "    # x.shape: [batch_size, z_dim] 64 128\n",
    "    #print(x.shape)\n",
    "    x = ly.fully_connected(x, 4 * 4 * 8 * Dim, activation_fn=lrelu, normalizer_fn=ly.batch_norm)\n",
    "    #print(x.shape)\n",
    "    x = tf.reshape(x, (-1, 4, 4, 8*Dim))\n",
    "    #print(x.shape)\n",
    "    if bn:\n",
    "      x = ly.conv2d_transpose(x, 4*Dim, 3, stride=2,activation_fn=tf.nn.relu, normalizer_fn=ly.batch_norm, padding='SAME', weights_initializer=tf.random_normal_initializer(0, 0.02))\n",
    "    else:\n",
    "      x = ly.conv2d_transpose(x, 4*Dim, 3, stride=2,activation_fn=tf.nn.relu, padding='SAME', weights_initializer=tf.random_normal_initializer(0, 0.02))\n",
    "    #print(x.shape)\n",
    "    if bn:\n",
    "      x = ly.conv2d_transpose(x, 2*Dim, 3, stride=2,activation_fn=tf.nn.relu, normalizer_fn=ly.batch_norm, padding='SAME', weights_initializer=tf.random_normal_initializer(0, 0.02))\n",
    "    else:\n",
    "      x = ly.conv2d_transpose(x, 2*Dim, 3, stride=2,activation_fn=tf.nn.relu, padding='SAME', weights_initializer=tf.random_normal_initializer(0, 0.02))\n",
    "    #print(x.shape)\n",
    "    if bn :\n",
    "      x = ly.conv2d_transpose(x, Dim, 3, stride=2,activation_fn=tf.nn.relu, normalizer_fn=ly.batch_norm, padding='SAME', weights_initializer=tf.random_normal_initializer(0, 0.02))\n",
    "    else:\n",
    "      x = ly.conv2d_transpose(x, Dim, 3, stride=2,activation_fn=tf.nn.relu, padding='SAME', weights_initializer=tf.random_normal_initializer(0, 0.02))\n",
    "    #print(x.shape)\n",
    "    x = ly.conv2d_transpose(x, channel, 3, stride=1,activation_fn=tf.nn.tanh, padding='SAME', weights_initializer=tf.random_normal_initializer(0, 0.02))\n",
    "\n",
    "   # print(x.name)\n",
    "    #print(x.shape)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8jp_H7cCWwgq"
   },
   "outputs": [],
   "source": [
    "def generator_mlp(n_samples,x=None):\n",
    "  #hidden layer size if mlp is chosen\n",
    "  if x is None:\n",
    "    x = sample_noise(n_samples, noise_dim)\n",
    "  with tf.variable_scope(\"generator\"):\n",
    "    train = ly.fully_connected(x, 4 * 4 * 8 * Dim, activation_fn=lrelu, normalizer_fn=ly.batch_norm)\n",
    "    train = ly.fully_connected(train, 4*Dim, activation_fn=lrelu, normalizer_fn=ly.batch_norm)\n",
    "    train = ly.fully_connected(train, 2*Dim, activation_fn=lrelu, normalizer_fn=ly.batch_norm)\n",
    "    train = ly.fully_connected(train, s*s*channel, activation_fn=tf.nn.tanh, normalizer_fn=ly.batch_norm)\n",
    "    train = tf.reshape(train, tf.stack([batch_size, s, s, channel]))\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "advgIwnkR7ur"
   },
   "outputs": [],
   "source": [
    "def discriminator(x,  reuse=False):\n",
    "\n",
    "  with tf.variable_scope('critic') as scope:\n",
    "    if reuse:\n",
    "      scope.reuse_variables()\n",
    "    init = tf.contrib.layers.xavier_initializer() # 初始化器\n",
    "    print('x0.shape:',x.shape)\n",
    "    x = tf.reshape(x, [-1,32,32,1])\n",
    "    print('x1.shape:',x.shape)\n",
    "    x = tf.layers.conv2d(x, 64, 4, activation=lrelu, strides=2, padding='valid',\n",
    "                         kernel_initializer=init, name='conv_0')\n",
    "    print('x2.shape:',x.shape)\n",
    "    x = tf.layers.conv2d(x, 128, 4, activation=lrelu, strides=2, padding='valid',\n",
    "                         kernel_initializer=init, name='conv_1')\n",
    "    print('x3.shape:',x.shape)\n",
    "    x = tf.layers.batch_normalization(x, name='batchnorm_0')\n",
    "    print('x4.shape:',x.shape)\n",
    "    x = tf.reshape(x, [-1,3200])\n",
    "    print('x5.shape:',x.shape)\n",
    "    x = tf.layers.dense(x, 1024, activation=lrelu, kernel_initializer=init, name='dense_0')\n",
    "    print('x6.shape:',x.shape)\n",
    "    logits = tf.layers.dense(x, 1, kernel_initializer=init, name='logits')\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HDwsP9a1X2yP"
   },
   "outputs": [],
   "source": [
    "def critic_conv(img, reuse=False):\n",
    "  with tf.variable_scope('critic') as scope:\n",
    "    if reuse:\n",
    "      scope.reuse_variables()\n",
    "    \n",
    "    img = ly.conv2d(img, num_outputs=Dim, kernel_size=3,stride=2, activation_fn=lrelu)\n",
    "    if bn :\n",
    "      img = ly.conv2d(img, num_outputs=2*Dim, kernel_size=3,stride=2, activation_fn=lrelu, normalizer_fn=ly.batch_norm)\n",
    "    else:\n",
    "      img = ly.conv2d(img, num_outputs=2*Dim, kernel_size=3,stride=2, activation_fn=lrelu)\n",
    "    if bn :\n",
    "      img = ly.conv2d(img, num_outputs=4*Dim, kernel_size=3,stride=2, activation_fn=lrelu)\n",
    "    else:\n",
    "      img = ly.conv2d(img, num_outputs=4*Dim, kernel_size=3,stride=2, activation_fn=lrelu)\n",
    "    if bn :\n",
    "      img = ly.conv2d(img, num_outputs=8*Dim, kernel_size=3,stride=2, activation_fn=lrelu)\n",
    "    else:\n",
    "      img = ly.conv2d(img, num_outputs=8*Dim, kernel_size=3,stride=2, activation_fn=lrelu)\n",
    "    \n",
    "    logit = ly.fully_connected(tf.reshape(img, [batch_size, -1]), 1, activation_fn=None)\n",
    "    return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vdZfnXFXX6q4"
   },
   "outputs": [],
   "source": [
    "def critic_mlp(img, reuse=False):\n",
    "  with tf.variable_scope('critic') as scope:\n",
    "    if reuse:\n",
    "      scope.reuse_variables()\n",
    "    img = ly.fully_connected(tf.reshape(img, [batch_size, -1]), 4*Dim, activation_fn=tf.nn.relu)\n",
    "    img = ly.fully_connected(img, 4*Dim, activation_fn=tf.nn.relu)\n",
    "    img = ly.fully_connected(img, Dim, activation_fn=tf.nn.relu)\n",
    "    logit = ly.fully_connected(img, 1, activation_fn=None)\n",
    "    return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xIUlRa5E0D3Z"
   },
   "outputs": [],
   "source": [
    "def wgan_loss(logits_real, logits_fake, batch_size, real_data, fake_data, critic):\n",
    "  \n",
    "  print(real_data.shape)\n",
    "  print(fake_data.shape)\n",
    "  if mode == \"wgan\":\n",
    "    c_loss = -tf.reduce_mean(logits_real) + tf.reduce_mean(logits_fake)\n",
    "    g_loss = -tf.reduce_mean(logits_fake)\n",
    "\n",
    "  elif mode == \"wgan-gp\":\n",
    "    c_loss = -tf.reduce_mean(logits_real) + tf.reduce_mean(logits_fake)\n",
    "    g_loss = -tf.reduce_mean(logits_fake)\n",
    "\n",
    "    alpha = tf.random_uniform([batch_size,1,1,1], minval=0.0, maxval=1.0) \n",
    "    differences = fake_data - real_data\n",
    "    interpolates = real_data + (alpha*differences)\n",
    "    gradients = tf.gradients(critic(interpolates,reuse=True), [interpolates])[0]\n",
    "    slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), reduction_indices=[1]))\n",
    "    gradient_penalty = tf.reduce_mean((slopes-1.)**2)\n",
    "    c_loss += lam*gradient_penalty\n",
    "  elif mode == \"dcgan\":\n",
    "    g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits_fake, labels=tf.ones_like(logits_fake)))\n",
    "    c_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits_fake, labels=tf.zeros_like(logits_fake)))\n",
    "    c_loss += tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits_real, labels=tf.ones_like(logits_real)))\n",
    "    c_loss/=2\n",
    "  \n",
    "  else:\n",
    "    print('------')\n",
    "  return c_loss, g_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lmwsVr9DefaV"
   },
   "outputs": [],
   "source": [
    "def model():\n",
    "  \n",
    "  x = tf.placeholder(dtype=tf.float32, shape=(batch_size, 32, 32, channel))\n",
    "  z = sample_noise(batch_size, noise_dim)\n",
    "  generator = generator_mlp if is_mlp else generator_conv\n",
    "  critic = critic_mlp if is_mlp else critic_conv\n",
    "  # critic = discriminator\n",
    "  train = generator(batch_size,z)\n",
    "  \n",
    "  logits_real = critic(x)\n",
    "  logits_fake = critic(train, reuse=True)\n",
    "\n",
    "  c_loss, g_loss = wgan_loss(logits_real, logits_fake, batch_size, x, train, critic)\n",
    "\n",
    "  g_loss_sum = tf.summary.scalar(\"g_loss\", g_loss)\n",
    "  c_loss_sum = tf.summary.scalar(\"c_loss\", c_loss)\n",
    "  img_sum = tf.summary.image(\"img\", train, max_outputs=16)\n",
    "\n",
    "  C_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,'critic')\n",
    "  G_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,'generator')\n",
    "\n",
    "\n",
    "  global_steps = tf.Variable(0, trainable=False)\n",
    "  if mode == 'wgan-gp':\n",
    "    opt_c = ly.optimize_loss(loss=c_loss, learning_rate=learning_rate_C,optimizer=partial(tf.train.AdamOptimizer, beta1=0.5, beta2=0.9), variables=C_vars, global_step=global_steps, summaries = ['gradient_norm'])\n",
    "    opt_g = ly.optimize_loss(loss=g_loss, learning_rate=learning_rate_G,optimizer=partial(tf.train.AdamOptimizer, beta1=0.5, beta2=0.9), variables=G_vars, global_step=global_steps, summaries = ['gradient_norm'])\n",
    "  elif mode == 'dcgan':\n",
    "    opt_c = ly.optimize_loss(loss=c_loss, learning_rate=learning_rate_C,optimizer=partial(tf.train.AdamOptimizer, beta1=0.5), variables=C_vars, global_step=global_steps, summaries = ['gradient_norm'])\n",
    "    opt_g = ly.optimize_loss(loss=g_loss, learning_rate=learning_rate_G,optimizer=partial(tf.train.AdamOptimizer, beta1=0.5), variables=G_vars, global_step=global_steps, summaries = ['gradient_norm'])\n",
    "  elif mode == 'wgan':\n",
    "    opt_c = ly.optimize_loss(loss=c_loss, learning_rate=learning_rate_C,optimizer=tf.train.RMSPropOptimizer, variables=C_vars, global_step=global_steps, summaries = ['gradient_norm'])\n",
    "    opt_g = ly.optimize_loss(loss=g_loss, learning_rate=learning_rate_G,optimizer=tf.train.RMSPropOptimizer, variables=G_vars, global_step=global_steps, summaries = ['gradient_norm'])\n",
    "    clipped_var_c = [tf.assign(var, tf.clip_by_value(var, clamp_lower, clamp_upper)) for var in C_vars]\n",
    "    # merge the clip operations on critic variables\n",
    "    with tf.control_dependencies([opt_c]):\n",
    "      opt_c = tf.tuple(clipped_var_c)\n",
    "  return opt_g, opt_c, x, train, c_loss, g_loss\n",
    "  # d_extra_step = tf.get_collection(tf.GraphKeys.UPDATE_OPS, 'critic')\n",
    "  # g_extra_step = tf.get_collection(tf.GraphKeys.UPDATE_OPS, 'generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cOpoYtWDGoHA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1NIymbAc1jns"
   },
   "outputs": [],
   "source": [
    "def next_feed_dict(real_data, dataset):\n",
    "  train_img = dataset.train.next_batch(batch_size)[0]\n",
    "  if data == 'cifar':\n",
    "    train_img = train_img.reshape((batch_size, 3, 32, 32))\n",
    "    train_img = train_img.transpose((0, 2, 3, 1))\n",
    "  train_img = 2*train_img-1\n",
    "  if data == 'mnist':\n",
    "    train_img = np.reshape(train_img, (-1, 28, 28))\n",
    "    npad = ((0, 0), (2, 2), (2, 2))\n",
    "    train_img = np.pad(train_img, pad_width=npad,mode='constant', constant_values=-1)\n",
    "    train_img = np.expand_dims(train_img, -1)\n",
    "  \n",
    "  feed_dict = {real_data: train_img}\n",
    "  return feed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tw4BbAglTXhG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "juBfCWqRhtHO"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "  \n",
    "  with tf.device(device):\n",
    "    opt_g, opt_c, real_data, fake_data, c_loss, g_loss =model()\n",
    "  if FID:\n",
    "    if data == 'cifar':\n",
    "      stats_path = '/content/stat/fid_stats_cifar10_train.npz'\n",
    "    elif data == 'svhn':\n",
    "      stats_path = '/content/stat/fid_stats_svhn_train.npz'\n",
    "    f = np.load(stats_path)\n",
    "    mu_real, sigma_real = f['mu'][:], f['sigma'][:]\n",
    "    f.close()\n",
    "    inception_path = fid.check_or_download_inception(None) # download inception network\n",
    "    fid.create_inception_graph(inception_path)  # load the graph into the current TF graph\n",
    "\n",
    "  if data=='svhn':\n",
    "    dataset = load_svhn()\n",
    "  elif data=='mnist':\n",
    "    dataset = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "  elif data=='cifar':\n",
    "    dataset = load_cifar() \n",
    "  merged_all = tf.summary.merge_all()\n",
    "  saver = tf.train.Saver()\n",
    "  config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)\n",
    "  #config.gpu_options.allow_growth = True\n",
    "  #config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "  with tf.Session(config=config) as sess:\n",
    "  #with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    summary_writer = tf.summary.FileWriter(log_dir, sess.graph)\n",
    "    fid_tfvar = tf.Variable(0.0, trainable=False)\n",
    "    fid_sum = tf.summary.scalar(\"FID\", fid_tfvar)\n",
    "    \n",
    "    for i in range(max_iter_step):\n",
    "      #if i < 25 or i % 500 == 0:\n",
    "       # citers = 100\n",
    "      start_time = time.time()\n",
    "      if mode =='dcgan':\n",
    "        citers = 1\n",
    "      else:\n",
    "        citers = Citers\n",
    "      # Critic\n",
    "      for j in range(citers):\n",
    "        feed_dict = next_feed_dict(real_data, dataset) #\n",
    "        if i%100 == 99 and j == 0:\n",
    "          run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
    "          run_metadata = tf.RunMetadata()\n",
    "\n",
    "          _, merged = sess.run([opt_c, merged_all], feed_dict=feed_dict,options=run_options, run_metadata=run_metadata)\n",
    "          summary_writer.add_summary(merged, i)\n",
    "          summary_writer.add_run_metadata(run_metadata, 'critic_metadata {}'.format(i), i)\n",
    "        \n",
    "        else:\n",
    "          _=sess.run(opt_c, feed_dict=feed_dict)\n",
    "      # Generator\n",
    "      feed_dict = next_feed_dict(real_data, dataset)\n",
    "      if i % 100 == 99:\n",
    "        _, merged = sess.run([opt_g, merged_all], feed_dict=feed_dict,options=run_options, run_metadata=run_metadata)\n",
    "        summary_writer.add_summary(merged, i)\n",
    "        summary_writer.add_run_metadata(run_metadata, 'generator_metadata {}'.format(i), i)\n",
    "        \n",
    "      else:\n",
    "        sess.run(opt_g, feed_dict=feed_dict) \n",
    "      if i % 1000 == 999:\n",
    "        saver.save(sess, os.path.join(ckpt_dir, \"model.ckpt\"), global_step=i)\n",
    "      \n",
    "\n",
    "      if(i % 500 == 0):\n",
    "       print(\"i:\",i)\n",
    "       _fake_data = sess.run(fake_data)\n",
    "       _fake_data = (_fake_data+1.0)/2\n",
    "       fig = disp_images(_fake_data,i)\n",
    "       plt.show()\n",
    "       #resize_function(fake_data, i)\n",
    "      if i % 500 == 499 and IS:\n",
    "        generator = generator_mlp if is_mlp else generator_conv\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "        samples_100 = generator(100)\n",
    "        def get_inception_score():\n",
    "          all_samples = []\n",
    "          for i in xrange(10):\n",
    "            all_samples.append(sess.run(samples_100))\n",
    "          all_samples = np.concatenate(all_samples, axis=0)\n",
    "          all_samples = ((all_samples+1.)*(255./2)).astype('int32')\n",
    "          #all_samples = all_samples.reshape((-1, 3, 32, 32)).transpose(0,2,3,1)\n",
    "          return fget_inception_score(list(all_samples))\n",
    "        inception_score = get_inception_score()\n",
    "        #print('inception score', inception_score[0])\n",
    "        plot.plot('inception score', inception_score[0])\n",
    "\n",
    "      if ((i < 5) or (i % 500 == 499)) and IS:\n",
    "          plot.flush()\n",
    "      if IS:\n",
    "        plot.tick()\n",
    "\n",
    "      if i % FID_STEP == 0:\n",
    "        samples = np.zeros((FID_EVAL_SIZE, s,s,channel))\n",
    "        n_fid_batches = FID_EVAL_SIZE // FID_SAMPLE_BATCH_SIZE\n",
    "        #n_fid_batches = 5\n",
    "        generator = generator_mlp if is_mlp else generator_conv\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "        for j in range(n_fid_batches):\n",
    "          print(\"\\rgenerate fid sample batch %d/%d \" % (j + 1, n_fid_batches), end=\"\", flush=True)\n",
    "          frm = j * FID_SAMPLE_BATCH_SIZE\n",
    "          to = frm + FID_SAMPLE_BATCH_SIZE\n",
    "\n",
    "          samples[frm:to] = sess.run(generator(FID_SAMPLE_BATCH_SIZE))\n",
    "\n",
    "        # Cast, reshape and transpose (BCHW -> BHWC)\n",
    "        samples = ((samples + 1.0) * 127.5).astype('uint8')\n",
    "        #samples = samples.reshape(FID_EVAL_SIZE, 3, DIM, DIM)\n",
    "        #samples = samples.transpose(0,2,3,1)\n",
    "        mu_gen, sigma_gen = fid.calculate_activation_statistics(samples,sess,batch_size=FID_BATCH_SIZE,verbose=True)\n",
    "        \n",
    "        print(\"calculate FID:\", end=\" \", flush=True)\n",
    "        try:\n",
    "          FIDv = fid.calculate_frechet_distance(mu_gen, sigma_gen, mu_real, sigma_real)\n",
    "        except Exception as e:\n",
    "          print(e)\n",
    "          FIDv=500\n",
    "        print(FIDv)\n",
    "        sess.run(tf.assign(fid_tfvar, FIDv))\n",
    "        summary_str = sess.run(fid_sum)\n",
    "        summary_writer.add_summary(summary_str, i)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1236268,
     "status": "error",
     "timestamp": 1643395259022,
     "user": {
      "displayName": "jiaming li",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07336273892212727484"
     },
     "user_tz": -480
    },
    "id": "_f6I6iyM3Uek",
    "outputId": "cb0c21a9-f0ed-448e-c885-b66aaec57680"
   },
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EuOq5-i07d-h"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "COHtWLD4wWJl"
   },
   "outputs": [],
   "source": [
    "#!cp '/content/log_wgan/eventsfidtest.out.tfevents.1643349973.36aea13ece8b' '/content/drive/MyDrive/test/result' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DC_YlBA5Uuxc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yr0ph3-NBWvC"
   },
   "outputs": [],
   "source": [
    "!cp -r \"/content/log_wgan\" \"/content/drive/MyDrive/test/result/dcgan-svhn-fid\"\n",
    "#!cp -r \"/content/ckpt_wgan\" \"/content/drive/MyDrive/test/result/wgan-gp-svhn-fid\"\n",
    "!cp -r \"/content/dcgan_svhn\" \"/content/drive/MyDrive/test/result/dcgan-svhn-fid\"\n",
    "#cp \"/content/log.pkl\" \"/content/drive/MyDrive/test/result/wgan-gp-svhn-fid\"\n",
    "#cp \"/content/inception_score.jpg\" \"/content/drive/MyDrive/test/result/wgan-gp-svhn-fid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FVQO7dV_DpFF"
   },
   "outputs": [],
   "source": [
    "import pylab\n",
    "read_file=open('log.pkl','rb')  \n",
    "img=pickle.load(read_file)\n",
    "read_file.close() \n",
    "for name in img:\n",
    "  x_vals = np.sort(list(img[name].keys()))\n",
    "  y_vals = [img[name][x] for x in x_vals]\n",
    "  plt.clf()\n",
    "  plt.plot(x_vals, y_vals)\n",
    "  plt.xlabel('iteration')\n",
    "  plt.ylabel(name)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n3t7z85zXMvQ"
   },
   "outputs": [],
   "source": [
    "'''train_img = dataset1.train.next_batch(batch)[0]\n",
    "img =train_img[1]\n",
    "print(img.shape)\n",
    "plt.imshow(img)\n",
    "#img = img.reshape((3, 32, 32)) # 将一维向量改变形状得到这样一个元组:(高,宽,通道数)\n",
    "#img = img.transpose((1, 2, 0))\n",
    "#print(img.shape)\n",
    "channel = 3\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ng6TwEweE6CG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RJs9gXpW3aSI"
   },
   "outputs": [],
   "source": [
    "'''batch = 16\n",
    "channel = 3\n",
    "\n",
    "train_img = dataset.train.next_batch(batch)[0]\n",
    "\n",
    "print(train_img.shape)\n",
    "img = train_img[1] \n",
    "print(img.shape)\n",
    "img = img.reshape((3, 32, 32)) # 将一维向量改变形状得到这样一个元组:(高,宽,通道数)\n",
    "img = img.transpose((1, 2, 0)) \n",
    "print(img.shape)\n",
    "plt.imshow(img)\n",
    "\n",
    "channel = 3\n",
    "\n",
    "\n",
    "train_img = train_img.reshape((batch, 3, 32, 32))\n",
    "train_img = train_img.transpose((0, 2, 3, 1)) \n",
    "print(train_img[0])\n",
    "print('train shape',train_img.shape)\n",
    "disp_images(train_img)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qzgY-MYUhtJu"
   },
   "outputs": [],
   "source": [
    "#!cp -r \"/content/drive/MyDrive/test/cifar-10-batches-py\" \"/content/cifar10\""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "wgan.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
